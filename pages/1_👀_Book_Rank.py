import re
import time

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from pathlib2 import Path
from pyspark import SparkConf
from pyspark.sql import SparkSession

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_extras.colored_header import colored_header
from streamlit_extras.mention import mention

book_fields_with_first_authors = "book_id,title,SUBSTRING_INDEX(authors, '/', 1) AS first_author,average_rating,language_code,text_reviews_count,publication_date,publisher"
DEBUG = False

# å®šä¹‰è‹±æ–‡åˆ—ååˆ°ä¸­æ–‡åˆ—åçš„æ˜ å°„å­—å…¸
column_name_mapping = {
    "book_id": "ä¹¦ç±ç¼–å·",
    "title": "ä¹¦å",
    "first_author": "ç¬¬ä¸€ä½œè€…",
    "average_rating": "å¹³å‡è¯„åˆ†",
    "language_code": "è¯­è¨€",
    "text_reviews_count": "ä¹¦é¢è¯„è®ºæ•°",
    "publication_date": "å‡ºç‰ˆæ—¥æœŸ",
    "publisher": "å‡ºç‰ˆç¤¾"
}


def date_covert(data):
    try:
        converted_date = pd.to_datetime(data, format="%m/%d/%Y")
        return converted_date.strftime("%Y-%m-%d")
    except ValueError:
        return np.nan


def convert_column_names(column_name):
    """
    å°†é©¼å³°å‘½åæ³•çš„åˆ—åè½¬æ¢ä¸ºä¸‹åˆ’çº¿å‘½åæ³•
     e.g. BookID --> book_id
    """
    return re.sub(r'([a-z])([A-Z])', r'\1_\2', column_name).lower()


def process_data(input_dir, output_dir):
    df = pd.read_csv(input_dir, on_bad_lines='skip')

    df.columns = df.columns.str.strip().map(convert_column_names)
    df.columns = df.columns.str.strip()
    df['publication_date'] = df['publication_date'].apply(lambda x: date_covert(x))
    df = df.dropna().drop_duplicates(keep='first')

    # åº”ç”¨åˆ—åæ˜ å°„åˆ°ä¸­æ–‡
    df.rename(columns=column_name_mapping, inplace=True)

    output_file = output_dir / f"{input_dir.stem}.csv"
    print(df['è¯­è¨€'].unique())
    df.to_csv(output_file, index=False, encoding='utf-8')

    print(f"Saved {output_file}")


def average_rating(spark, count):
    """
     æ ¹æ® average_rating(è¯¥ä¹¦æ”¶åˆ°çš„ä¹¦é¢æ–‡æœ¬è¯„è®ºæ€»æ•°) ç»Ÿè®¡å‰ count æœ¬ä¹¦ç±
    :param count:
    :param spark: spark instance
    :return: saved file
    """
    book_list = spark.sql(f"SELECT {book_fields_with_first_authors} FROM books \
                                  ORDER BY average_rating DESC")
    return book_list.limit(count)


def num_pages(spark, count):
    """
     æ ¹æ® num_pages(ä¸»ä¹¦é¡µæ•°) ç»Ÿè®¡å‰ count æœ¬ä¹¦ç±
    :param spark: spark instance
    :param count: top sum
    :return: saved file
    """
    book_list = spark.sql(f"SELECT {book_fields_with_first_authors} FROM books \
                              ORDER BY num_pages DESC")
    return book_list.limit(count)


def ratings_count(spark, count):
    """
     æ ¹æ® ratings_count(æ”¶åˆ°çš„å”¯ä¸€è¯„åˆ†æ•°é‡) ç»Ÿè®¡å‰ count æœ¬ä¹¦ç±
    :param spark: spark instance
    :param count: top sum
    :return: saved file
    """
    book_list = spark.sql(f"SELECT {book_fields_with_first_authors} FROM books \
                              ORDER BY ratings_count DESC")
    return book_list.limit(count)


def text_reviews_count(spark, count):
    """
     æ ¹æ® text_reviews_count(è¯¥ä¹¦æ”¶åˆ°çš„ä¹¦é¢æ–‡æœ¬è¯„è®ºæ€»æ•°) ç»Ÿè®¡å‰ count æœ¬ä¹¦ç±
    :param spark: spark instance
    :param count: top sum
    :return: saved file
    """
    book_list = spark.sql(f"SELECT {book_fields_with_first_authors} FROM books \
                          ORDER BY text_reviews_count DESC")
    return book_list.limit(count)


@st.cache_resource
def get_spark_connection(cleaned_data_path):
    progress_bar = st.progress(0)  # åˆ›å»ºè¿›åº¦æ¡
    # æ¨¡æ‹Ÿè¿›åº¦é€æ­¥æ›´æ–°
    for i in range(1, 101, 20):
        time.sleep(0.1)  # æ¯æ¬¡ç¡çœ æ¨¡æ‹Ÿä»»åŠ¡è€—æ—¶
        progress_bar.progress(i)  # æ›´æ–°è¿›åº¦æ¡
    spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()
    books_df = spark.read.csv(str(cleaned_data_path / "books-kaggle-mohamadreza-momeni.csv"), header=True,
                              inferSchema=True)
    books_df = books_df.repartition(1)
    books_df.createOrReplaceTempView("books")
    progress_bar.progress(100)
    return spark


def main():
    st.title("ğŸ“š å›¾ä¹¦æ•°æ®åˆ†æå±•ç¤º")
    colored_header("ğŸ” æ•°æ®å¤„ç†å’Œå±•ç¤ºå¹³å°", "é€šè¿‡å¤šä¸ªç»´åº¦å±•ç¤ºå›¾ä¹¦æ•°æ®", color_name="blue-70")

    st.markdown("> ğŸ“¦ æ­£åœ¨åŠ è½½èµ„æº...")
    add_vertical_space(1)  # åœ¨ç•Œé¢å¢åŠ ä¸€äº›å‚ç›´é—´è·

    # data etl
    root_path = Path(__file__).resolve().parents[1]
    uncleaned_data_path = root_path / "data" / "uncleaned"
    cleaned_data_path = root_path / "data" / "cleaned"

    if not cleaned_data_path.exists():
        for file in uncleaned_data_path.glob("*.csv"):
            process_data(file, cleaned_data_path)

    spark = get_spark_connection(cleaned_data_path)

    if not DEBUG:

        # æ·»åŠ é€‰æ‹©æ¡†ç”¨äºé€‰æ‹©ç»Ÿè®¡ç±»å‹
        analysis_type = st.sidebar.selectbox(
            "ğŸ“Š é€‰æ‹©åˆ†æçš„ç±»åˆ«",  # æ·»åŠ æç¤ºå’Œå›¾æ ‡
            ("å¹³å‡è¯„åˆ†æœ€é«˜çš„ä¹¦ç±", "é¡µé¢æœ€å¤šçš„ä¹¦ç±", "è¯„åˆ†æ•°é‡æœ€å¤šçš„ä¹¦ç±", "ä¹¦é¢è¯„è®ºæœ€å¤šçš„ä¹¦ç±"),
            help="é€‰æ‹©æ‚¨è¦åˆ†æçš„ä¹¦ç±æ•°æ®ç±»å‹"
        )

        count = st.sidebar.slider("ğŸ“ˆ é€‰æ‹©å‰å‡ æœ¬ä¹¦ç±", 5, 5000, 10, help="é€‰æ‹©è¦å±•ç¤ºçš„ä¹¦ç±æ•°é‡")

        # æŒ‰ç…§é€‰æ‹©çš„ç±»å‹å±•ç¤ºç»“æœ
        if analysis_type == "å¹³å‡è¯„åˆ†æœ€é«˜çš„ä¹¦ç±":
            st.write(f"ğŸ“ˆ å‰ {count} æœ¬å¹³å‡è¯„åˆ†æœ€é«˜çš„ä¹¦ç±")
            result = average_rating(spark, count)
        elif analysis_type == "é¡µé¢æœ€å¤šçš„ä¹¦ç±":
            st.write(f"ğŸ“š å‰ {count} æœ¬é¡µé¢æœ€å¤šçš„ä¹¦ç±")
            result = num_pages(spark, count)
        elif analysis_type == "è¯„åˆ†æ•°é‡æœ€å¤šçš„ä¹¦ç±":
            st.write(f"ğŸŒŸ å‰ {count} æœ¬è¯„åˆ†æ•°é‡æœ€å¤šçš„ä¹¦ç±")
            result = ratings_count(spark, count)
        else:
            st.write(f"âœï¸ å‰ {count} æœ¬ä¹¦é¢è¯„è®ºæœ€å¤šçš„ä¹¦ç±")
            result = text_reviews_count(spark, count)

        df = result.toPandas()

        # åº”ç”¨åˆ—åæ˜ å°„åˆ°ä¸­æ–‡
        df.rename(columns=column_name_mapping, inplace=True)

        # åˆ†é¡µå±•ç¤ºæ•°æ®
        items_per_page = 10
        total_pages = len(df) // items_per_page + (1 if len(df) % items_per_page != 0 else 0)
        current_page = st.sidebar.number_input("ğŸ“„ é€‰æ‹©é¡µç ", min_value=1, max_value=total_pages, value=1, step=1)

        # è®¡ç®—å½“å‰é¡µçš„èµ·å§‹å’Œç»“æŸç´¢å¼•
        start_idx = (current_page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        df_page = df.iloc[start_idx:end_idx]

        # å±•ç¤ºå½“å‰é¡µçš„æ•°æ®
        st.markdown(f"### ğŸ“‹ ç¬¬ {current_page}/{total_pages} é¡µ")
        st.table(df_page)

        # æ•°æ®å¯è§†åŒ– - ä½¿ç”¨å¤šç§å›¾è¡¨ç±»å‹å±•ç¤ºæ•°æ®
        # æ•°æ®å¯è§†åŒ– - ä½¿ç”¨å¤šç§å›¾è¡¨ç±»å‹å±•ç¤ºæ•°æ®
        st.markdown("### æ•°æ®å¯è§†åŒ– ğŸ“Š")
        with st.expander("ğŸ” å±•å¼€ä»¥æŸ¥çœ‹æ•°æ®å¯è§†åŒ–å›¾è¡¨"):

            # 1. æ ¸å¯†åº¦ä¼°è®¡å›¾å±•ç¤ºè¯„åˆ†çš„æ•´ä½“åˆ†å¸ƒ
            st.markdown("#### è¯„åˆ†çš„æ•´ä½“åˆ†å¸ƒæƒ…å†µ ğŸ“Š")
            kde_chart = alt.Chart(df).transform_density(
                'å¹³å‡è¯„åˆ†',
                as_=['å¹³å‡è¯„åˆ†', 'density'],
            ).mark_area().encode(
                x='å¹³å‡è¯„åˆ†:Q',
                y='density:Q'
            ).properties(
                width=600,
                height=300,
                title='è¯„åˆ†åˆ†å¸ƒå¯†åº¦å›¾'
            )
            st.altair_chart(kde_chart)

            # 2. ç´¯ç§¯åˆ†å¸ƒå‡½æ•° (CDF) å›¾è¡¨å±•ç¤ºè¯„åˆ†çš„ç´¯ç§¯æƒ…å†µ
            st.markdown("#### è¯„åˆ†çš„ç´¯ç§¯åˆ†å¸ƒæƒ…å†µ (CDF) ğŸ“Š")
            cdf_chart = alt.Chart(df).transform_window(
                cumulative_count='count()',  # ç´¯åŠ è®°å½•æ•°é‡
                sort=[{'field': 'å¹³å‡è¯„åˆ†'}]  # æŒ‰â€œå¹³å‡è¯„åˆ†â€æ’åº
            ).mark_line().encode(
                x='å¹³å‡è¯„åˆ†:Q',
                y='cumulative_count:Q'
            ).properties(
                width=600,
                height=300,
                title='è¯„åˆ†ç´¯ç§¯åˆ†å¸ƒå‡½æ•° (CDF)'
            )
            st.altair_chart(cdf_chart)

            # 3. è¯„åˆ†åŒºé—´é‡æ–°åˆ’åˆ†ï¼ˆå¢åŠ æ›´å¤šåŒºé—´åˆ’åˆ†ï¼‰
            st.markdown("#### è¯„åˆ†åŒºé—´é‡æ–°åˆ’åˆ† ğŸ“Š")
            bins = [0, 2.5, 3, 3.5, 4, 4.25, 4.5, 4.75, 5]
            labels = ['<2.5', '2.5-3', '3-3.5', '3.5-4', '4-4.25', '4.25-4.5', '4.5-4.75', '4.75-5']
            df['è¯„åˆ†åŒºé—´'] = pd.cut(df['å¹³å‡è¯„åˆ†'], bins=bins, labels=labels)
            binned_chart = alt.Chart(df).mark_bar().encode(
                x=alt.X('è¯„åˆ†åŒºé—´:N', title='è¯„åˆ†åŒºé—´'),
                y=alt.Y('count():Q', title='ä¹¦ç±æ•°é‡'),
                color='è¯„åˆ†åŒºé—´:N',
                tooltip=['è¯„åˆ†åŒºé—´', 'count()']
            ).properties(
                width=600,
                height=300,
                title='é‡æ–°åˆ†ç»„çš„è¯„åˆ†åŒºé—´åˆ†å¸ƒ'
            )
            st.altair_chart(binned_chart)

            # 4. ä½¿ç”¨ç®±çº¿å›¾å±•ç¤ºè¯„åˆ†åˆ†å¸ƒçš„ç»†èŠ‚ï¼ŒåŒ…æ‹¬ä¸­ä½æ•°å’Œå››åˆ†ä½æ•°
            st.markdown("#### è¯„åˆ†åˆ†å¸ƒçš„ç®±çº¿å›¾ ğŸ“¦")
            box_chart = alt.Chart(df).mark_boxplot().encode(
                y=alt.Y('å¹³å‡è¯„åˆ†:Q', title='è¯„åˆ†'),
                color=alt.value('teal')
            ).properties(
                width=600,
                height=300,
                title='è¯„åˆ†çš„ç®±çº¿å›¾'
            )
            st.altair_chart(box_chart)

            # 5. è¯„åˆ†åç¦»å¹³å‡å€¼çš„æƒ…å†µ
            st.markdown("#### è¯„åˆ†åç¦»å¹³å‡å€¼çš„æƒ…å†µ ğŸ”")
            overall_mean_rating = df['å¹³å‡è¯„åˆ†'].mean()
            df['è¯„åˆ†åç¦»'] = df['å¹³å‡è¯„åˆ†'] - overall_mean_rating
            deviation_chart = alt.Chart(df).mark_bar().encode(
                x=alt.X('è¯„åˆ†åç¦»:Q', title='è¯„åˆ†åç¦»'),
                y=alt.Y('count():Q', title='ä¹¦ç±æ•°é‡'),
                color=alt.condition(
                    alt.datum['è¯„åˆ†åç¦»'] > 0,  # æ¡ä»¶ï¼šåç¦»å€¼å¤§äº0
                    alt.value('steelblue'),  # æ­£åç¦»ä¸ºè“è‰²
                    alt.value('orange')  # è´Ÿåç¦»ä¸ºæ©™è‰²
                ),
                tooltip=['ä¹¦å', 'è¯„åˆ†åç¦»']
            ).properties(
                width=600,
                height=300,
                title='è¯„åˆ†åç¦»å¹³å‡å€¼çš„åˆ†å¸ƒ'
            )
            st.altair_chart(deviation_chart)

            # 6. è¯­è¨€åˆ†å¸ƒæ¡å½¢å›¾
            st.markdown("#### è¯­è¨€åˆ†å¸ƒæƒ…å†µ ğŸŒ")
            language_chart = alt.Chart(df).mark_bar().encode(
                x=alt.X('è¯­è¨€:N', title='è¯­è¨€'),
                y=alt.Y('count():Q', title='ä¹¦ç±æ•°é‡'),
                color='è¯­è¨€:N',
                tooltip=['è¯­è¨€', 'count()']
            ).properties(
                width=600,
                height=300,
                title='ä¸åŒè¯­è¨€ä¹¦ç±çš„åˆ†å¸ƒ'
            )
            st.altair_chart(language_chart)

            # 7. è¯„åˆ†ä¸ä¹¦é¢è¯„è®ºæ•°åŒè½´å›¾
            st.markdown("#### è¯„åˆ†ä¸ä¹¦é¢è¯„è®ºæ•°ä¹‹é—´çš„å…³ç³» ğŸ”„")
            dual_axis_chart = alt.Chart(df).mark_circle(size=60).encode(
                x=alt.X('ä¹¦é¢è¯„è®ºæ•°:Q', title='ä¹¦é¢è¯„è®ºæ•°'),
                y=alt.Y('å¹³å‡è¯„åˆ†:Q', title='å¹³å‡è¯„åˆ†'),
                color='è¯­è¨€:N',
                tooltip=['ä¹¦å', 'å¹³å‡è¯„åˆ†', 'ä¹¦é¢è¯„è®ºæ•°']
            ).properties(
                width=600,
                height=400,
                title='ä¹¦é¢è¯„è®ºæ•°ä¸å¹³å‡è¯„åˆ†çš„å…³ç³»'
            )
            st.altair_chart(dual_axis_chart)

        # å¢åŠ ä¹¦ç±è¯¦ç»†ä¿¡æ¯å±•ç¤º
        with st.expander("ğŸ“– å±•å¼€ä»¥æŸ¥çœ‹ä¹¦ç±è¯¦ç»†ä¿¡æ¯"):
            selected_book = st.selectbox("", df["ä¹¦å"], help="é€‰æ‹©è¦æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯çš„ä¹¦ç±")

            # æ ¹æ®é€‰æ‹©çš„ä¹¦åå±•ç¤ºè¯¦ç»†ä¿¡æ¯
            book_details = df[df["ä¹¦å"] == selected_book].iloc[0]

            # ä½¿ç”¨ Markdown å±•ç¤ºä¹¦ç±è¯¦ç»†ä¿¡æ¯
            st.markdown(f"""
            ### ğŸ“– {book_details["ä¹¦å"]}
            - **âœï¸ ä½œè€…**: {book_details["ç¬¬ä¸€ä½œè€…"]}
            - **â­ å¹³å‡è¯„åˆ†**: {book_details["å¹³å‡è¯„åˆ†"]}
            - **ğŸŒ è¯­è¨€**: {book_details["è¯­è¨€"]}
            - **ğŸ’¬ ä¹¦é¢è¯„è®ºæ•°**: {book_details["ä¹¦é¢è¯„è®ºæ•°"]}
            - **ğŸ“… å‡ºç‰ˆæ—¥æœŸ**: {book_details["å‡ºç‰ˆæ—¥æœŸ"]}
            - **ğŸ¢ å‡ºç‰ˆç¤¾**: {book_details["å‡ºç‰ˆç¤¾"]}
            """)

    mention(label="ğŸ”— æ•°æ®æº", url="https://www.kaggle.com/mohamadrezamomeni/goodreads-book-datasets-10m", icon="ğŸ“")


if __name__ == "__main__":
    main()